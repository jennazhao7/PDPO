{"cells":[{"cell_type":"code","source":["import os\n","os.environ['WANDB_DISABLED'] = 'true'"],"metadata":{"id":"koN_B4HmXTRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwyvxUzhfzU9"},"outputs":[],"source":["# install all dependencies\n","%%capture\n","\n","!pip install -q -U peft transformers datasets bitsandbytes trl accelerate\n","!pip install --upgrade transformers, datasets==2.16.1, accelerate==0.26.1, evaluate==0.4.1, bitsandbytes==0.42.0, trl, peft==0.8.2\n","\n"]},{"cell_type":"code","source":["# Library\n","%%capture\n","\n","from huggingface_hub import hf_hub_download\n","\n","import transformers\n","import torch\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from transformers import TrainingArguments\n","from peft import LoraConfig, AutoPeftModelForCausalLM\n","from datasets import load_dataset, Dataset\n","from trl import SFTTrainer, DPOTrainer\n","from huggingface_hub import notebook_login\n","\n","# Ignore warings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"QDpLglqDWEID"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["51f3e3664ad24ee4b8d00370291bf484","f97c690409ce4573a5857a0740d5d904","e9bf8684551c43ee886c89919d847a76","cd53da88ba5943e58c1772f018b2e2fa","e60cc8bd242e4787b2982153f536d3a0","33a6a95105dd435383453275626f57bd","4e7ba6aa463f4c31bef2989e8a269c56","a462f430bbbf44798fb7f538c5e84f0e","8aa9a397e9ac40fe9bdd3240dcaf6e31","ae9feeb21e904dcda5e42a728fc8aeb4","1324cfb1392e4ac3a8998a6cbac275e1","ed5cb647d8e6447d842d51cf855d7ac9","353b9b4d378e4590ba3e3870d6ba47f5","3385b7468bd24d43abc60f4f7af7acff","e02f93bf98f14eb3be5b5cb724a48a28","05d4e00806db4c5d94ecb96f0acfabae","f92d1d324d3b41c1baa82a28e2a5ad94","7f25bb00b2db4fa6995249770c4d1007","a4014d4faa6344b7b5e4d6bf041b385b","934afe92c982426d9781d6ef8ada2720"]},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1737882969319,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"},"user_tz":420},"id":"pHQXBABSgkuZ","outputId":"177bff6d-2b99-428c-de33-f59ec13d8b09"},"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51f3e3664ad24ee4b8d00370291bf484"}},"metadata":{}}],"source":["# log in to the Hugging Face hub (required for private datasets/models)\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m36R4fmx0h8Q"},"outputs":[],"source":["## Check my parameter size\n","\n","def print_trainable_params(model):\n","    total_params = 0\n","    trainable_params  = 0\n","    for name, param in model.named_parameters():\n","        total_params += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || total params: {total_params} || trainable%: {100 * trainable_params / total_params}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LnrQxwmBQKCI"},"outputs":[],"source":["#dataset_dpo = load_dataset(\"jondurbin/truthy-dpo-v0.1\", split=\"train[:150]\")\n","dataset_dpo = load_dataset(\"jondurbin/truthy-dpo-v0.1\", split=\"train[150:900]\")\n","\n","print(dataset_dpo.shape)\n","\n","df_dpo = dataset_dpo.to_pandas()\n","df_dpo.head()\n","\n","# keep rows with 'system' column = 'You are an unbiased, uncensored, helpful assistant.'\n","df_dpo = df_dpo[df_dpo[\"system\"] == \"You are an unbiased, uncensored, helpful assistant.\"]\n","df_dpo.head()\n","\n","# keep only columns 'prompt', 'chosen', 'rejected'\n","df_dpo = df_dpo[[\"prompt\", \"chosen\", \"rejected\"]]\n","\n","# change every text in promt from str to user: str. asistent:\n","df_dpo[\"prompt\"] = df_dpo[\"prompt\"].apply(lambda x: \"### USER: \" + x + \"\\n### ASSISTANT: \")\n","filtered_dataset = Dataset.from_pandas(df_dpo)\n","print(df_dpo.shape)\n","df_dpo.head()\n","\n"]},{"cell_type":"code","source":["# partition this dataset into 2 parts\n","\n","filtered_dataset_d1 = filtered_dataset.select(range(254))\n","filtered_dataset_d2 = filtered_dataset.select(range(254, 508))\n"],"metadata":{"id":"qZLD5JkzWZ1Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aBs43CWCTCu"},"outputs":[],"source":["## Random Response\n","import random\n","import numpy as np\n","\n","# epsilon = 2\n","# epsilon = 1\n","epsilon = 0.5\n","# epsilon = 0.1\n","# epsilon = 0\n","fliping = (1) /(np.exp(epsilon)+1)\n","# inf\n","\n","def switch_chosen_rejected(example):\n","  if random.random() < fliping:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"rejected\"], \"rejected\": example[\"chosen\"]}\n","  else:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"chosen\"], \"rejected\": example[\"rejected\"]}\n","\n","filtered_dataset_d1 = filtered_dataset_d1.map(switch_chosen_rejected)\n","filtered_dataset_d2 = filtered_dataset_d2.map(switch_chosen_rejected)\n","\n","print(fliping)"]},{"cell_type":"code","source":["# Sanity check: precentage of 0 in noisy labels\n","\n","# def difference_check(dataset1, dataset2):\n","\n","#   label_list = []\n","#   for i in range(len(dataset2)):\n","#     if dataset2[i][\"chosen\"] == dataset1[i + len(dataset1) - len(dataset2)][\"chosen\"] and dataset2[i][\"rejected\"] == dataset1[i + len(dataset1) - len(dataset2)][\"rejected\"]:\n","#       label_list.append(1)\n","#     else:\n","#       label_list.append(0)\n","#\n","#   return label_list\n","# noisy_label_d2= difference_check(filtered_dataset_d2, filtered_dataset.select(range(304, 608)))\n","\n","# noisy_label_zero_count = noisy_label_d2.count(0)\n","# total_noisy_labels = len(noisy_label_d2)\n","# percentage_zero = (noisy_label_zero_count / total_noisy_labels) * 100\n","\n","# print(f\"Percentage of 0 in noisy labels: {percentage_zero:.2f}%\")\n","## should be close to # fliping"],"metadata":{"id":"zph1CbGnQsye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pass privacy barrier, filtered_dataset_d2 is standard\n","noisy_label_d2 = [1] * len(filtered_dataset_d2)"],"metadata":{"collapsed":true,"id":"w76yxl7zedJT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wC27mYK9G7qZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737884734891,"user_tz":420,"elapsed":8048,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}},"outputId":"6f7cbb99-e9e5-4664-88cf-82c0ff616595"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":54}],"source":["## Load my tokenizer\n","tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2-large')\n","if tokenizer.pad_token_id is None:\n","  tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","## load my model\n","huggingface_filepath = hf_hub_download(repo_id=\"your/huggingface/model\", filename=\"policy.pt\")\n","model = transformers.AutoModelForCausalLM.from_pretrained('gpt2-large')\n","model.load_state_dict(torch.load(huggingface_filepath, map_location=torch.device('cuda'))['state'])\n","\n","## Self referencing\n","\n","## Load my tokenizer\n","tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2-large')\n","if tokenizer.pad_token_id is None:\n","  tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","## load my model\n","huggingface_filepath = hf_hub_download(repo_id=\"your/huggingface/model\", filename=\"policy.pt\")\n","model_ref = transformers.AutoModelForCausalLM.from_pretrained('gpt2-large')\n","model_ref.load_state_dict(torch.load(huggingface_filepath, map_location=torch.device('cuda'))['state'])\n","\n","## Self referencing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvooPLCHSSds"},"outputs":[],"source":["from trl import DPOTrainer\n","from trl import DPOConfig\n","\n","DPO_model_id = \"your/huggingface/model\"\n","\n","# Training arguments\n","training_arguments = DPOConfig(\n","    output_dir = DPO_model_id,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    learning_rate=5e-5,\n","    lr_scheduler_type=\"cosine\",\n","    ## epochs\n","    num_train_epochs = 3,\n","    ## max_steps=200,\n","    save_strategy=\"no\",\n","    logging_steps=1,\n","    optim=\"paged_adamw_32bit\",\n","    warmup_steps=10,\n","    bf16=True,\n","    report_to=None,\n","    push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TR5YNZMhSlri"},"outputs":[],"source":["from trl import DPOTrainer\n","\n","dpo_trainer = DPOTrainer(\n","    model,          # base model from SFT pipeline\n","    model_ref,             # typically a copy of the SFT trained base model\n","\n","    # beta=0.1,              # temperature hyperparameter of DPO\n","    train_dataset=filtered_dataset_d1, # dataset prepared above\n","    tokenizer=tokenizer,   # tokenizer\n","    args=training_arguments,    # training arguments e.g. batch size, lr, etc.\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpitMcsCTApx","collapsed":true},"outputs":[],"source":["# First stage train\n","dpo_trainer.train()"]},{"cell_type":"code","source":["dpo_trainer.state.log_history\n","\n","train_loss = [log['loss'] for log in dpo_trainer.state.log_history if 'loss' in log]\n","print(train_loss)"],"metadata":{"id":"Ctwnz7GbQ_6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Copied from Mitchell\n","## get log probabilites of given labels\n","\n","def _get_batch_logps(logits: torch.FloatTensor, labels: torch.LongTensor, average_log_prob: bool = False) -> torch.FloatTensor:\n","    \"\"\"Compute the log probabilities of the given labels under the given logits.\n","\n","    Args:\n","        logits: Logits of the model (unnormalized). Shape: (batch_size, sequence_length, vocab_size)\n","        labels: Labels for which to compute the log probabilities. Label tokens with a value of -100 are ignored. Shape: (batch_size, sequence_length)\n","        average_log_prob: If True, return the average log probability per (non-masked) token. Otherwise, return the sum of the log probabilities of the (non-masked) tokens.\n","\n","    Returns:\n","        A tensor of shape (batch_size,) containing the average/sum log probabilities of the given labels under the given logits.\n","    \"\"\"\n","    assert logits.shape[:-1] == labels.shape\n","\n","    labels = labels[:, 1:].clone()\n","    logits = logits[:, :-1, :]\n","    loss_mask = (labels != -100)\n","\n","    # dummy token; we'll ignore the losses on these tokens later\n","    labels[labels == -100] = 0\n","\n","    per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n","\n","    if average_log_prob:\n","        return (per_token_logps * loss_mask).sum(-1) / loss_mask.sum(-1)\n","    else:\n","        return (per_token_logps * loss_mask).sum(-1)\n"],"metadata":{"id":"stQ3A42QeT7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model infer on dataset\n","\n","def get_model_label(model, dataset, tokenizer):\n","  \"\"\"\n","  Generates model_label, a list of binary labels indicating whether the model prefers the chosen response over the rejected response for each example in the dataset.\n","\n","  Args:\n","    model: The model to evaluate.\n","    dataset: The dataset to evaluate the model on.\n","    tokenizer: The tokenizer to use for the model.\n","\n","  Returns:\n","    A list of binary labels (1 or 0) where 1 indicates that the model prefers the first response and 0 indicates that it prefers the second response.\n","  \"\"\"\n","\n","  def get_log_probs(prompt, response):\n","    inputs = tokenizer(prompt+response, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model(**inputs)\n","    log_probs = _get_batch_logps(outputs.logits, inputs.input_ids)\n","    return log_probs.item()\n","\n","  model_label = []\n","  for example in dataset:\n","      prompt = example[\"prompt\"]\n","      # example [\"first\"]\n","      chosen_response = example[\"chosen\"]\n","      chosen_log_prob = get_log_probs(prompt, chosen_response)\n","      # example [\"second\"]\n","      rejected_response = example[\"rejected\"]\n","      rejected_log_prob = get_log_probs(prompt, rejected_response)\n","\n","      if chosen_log_prob > rejected_log_prob:\n","          model_label.append(1)\n","      else:\n","          model_label.append(0)\n","\n","  return model_label\n"],"metadata":{"id":"wZ3ZEIUCjmEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# As if model is injecting a noise\n","\n","def calculate_model_flipping(noisy_label_list, model_prediction_list, flipping_score):\n","  \"\"\"Calculates the model flipping score given two lists and a flipping score.\n","\n","  Args:\n","    noisy_label_list: A list of noisy labels.\n","    model_prediction_list: A list of model predictions.\n","    flipping_score: The flipping score.\n","\n","  Returns:\n","    The model flipping score.\n","  \"\"\"\n","\n","  result_xor = [a ^ b for a, b in zip(noisy_label_list, model_prediction_list)]\n","  average_score = sum(result_xor) / len(result_xor)\n","  model_flipping = (average_score - flipping_score) / (1 - 2 * flipping_score)\n","  return model_flipping"],"metadata":{"id":"FS7Jo5W5kA7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Determine model flipping rate\n","model_label_d2 = get_model_label(model, filtered_dataset_d2, tokenizer)\n"],"metadata":{"id":"buwDPfweibM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## model_flipping\n","model_fliping = calculate_model_flipping(model_label_d2, noisy_label_d2, fliping)\n","print(f\"Model_fliping: {model_fliping}\")\n","print(f\"Noise_fliping: {fliping}\")\n"],"metadata":{"id":"-UT6zxHvgOam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Elementwise MAP estimator\n","\n","def MAP_estimator (lrr, lm, fliping, model_fliping):\n","\n","  map_label = []\n","  for i in range(len(lrr)):\n","    decision_ruler = (1 - 2*lrr[i])* np.log((1-fliping)/(fliping)) + (1 - 2*lm[i])* np.log((1-model_fliping)/(model_fliping))\n","    # print(decision_ruler)\n","    if decision_ruler > 0:\n","      map_label.append(0)\n","    else:\n","      map_label.append(1)\n","  return map_label\n","\n","MAP_label = MAP_estimator(noisy_label_d2, model_label_d2, fliping, model_fliping)\n","# print(MAP_label)"],"metadata":{"collapsed":true,"id":"ublj6Mm5W_dI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get my MAP dataset\n","def switch_chosen_rejected_MAP(example, label):\n","  if label == 0:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"rejected\"], \"rejected\": example[\"chosen\"]}\n","  else:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"chosen\"], \"rejected\": example[\"rejected\"]}\n","\n","MAP_dataset_d2 = filtered_dataset_d2.map(lambda example, idx: switch_chosen_rejected_MAP(example, MAP_label[idx]), with_indices=True)"],"metadata":{"collapsed":true,"id":"zSRxJPWxcSaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sanity check: Error rate\n","## Error rate estimation: min of fliping probability\n","def min_of_two(a, b):\n","  if a < b:\n","    return a\n","  else:\n","    return b\n","\n","error_rate = min_of_two(fliping, model_fliping)\n","print(f\"Result: {error_rate}\")"],"metadata":{"id":"ViK7aLofnqYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Training arguments\n","training_arguments = DPOConfig(\n","    output_dir = DPO_model_id,\n","\n","    # label_smoothing_factor= error_rate,\n","    # loss_type=\"robust\",\n","\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    learning_rate=5e-5,\n","    lr_scheduler_type=\"cosine\",\n","    ## epochs\n","    num_train_epochs = 2,\n","    ## max_steps=200,\n","    save_strategy=\"no\",\n","    logging_steps=1,\n","    optim=\"paged_adamw_32bit\",\n","    warmup_steps=10,\n","    bf16=True,\n","    # report_to=\"wandb\",\n","    push_to_hub=True,\n",")"],"metadata":{"id":"xOid3Xu6peYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resume training\n","dpo_trainer = DPOTrainer(\n","    model,          # base model from SFT pipeline\n","    model_ref,             # typically a copy of the SFT trained base model\n","\n","    # beta=0.1,              # temperature hyperparameter of DPO\n","    train_dataset=MAP_dataset_d2, # dataset prepared above\n","    tokenizer=tokenizer,   # tokenizer\n","    args=training_arguments,    # training arguments e.g. batch size, lr, etc.\n",")\n"],"metadata":{"id":"SifwBQNnmEVr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Second stage train\n","dpo_trainer.train()"],"metadata":{"id":"i7-6qUpZmEYL","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpo_trainer.state.log_history\n","\n","train_loss2= [log['loss'] for log in dpo_trainer.state.log_history if 'loss' in log]\n","train_loss.extend(train_loss2)\n"],"metadata":{"id":"Eqvk3IbnRsnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_loss)\n","plt.xlabel('Step')\n","plt.ylabel('Training Loss')\n","plt.title('Training Loss over Steps')\n","plt.show()\n"],"metadata":{"id":"H4pFRjSORspt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpo_trainer.model.push_to_hub(\"your/huggingface/model\")"],"metadata":{"id":"Pi6YZBU0Rsr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mKoizJUa3en_"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/Lior-Baruch/LLM-Advanced-FineTuning/blob/main/SFT_DPO_llama_2.ipynb","timestamp":1727550706165}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"51f3e3664ad24ee4b8d00370291bf484":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_4e7ba6aa463f4c31bef2989e8a269c56"}},"f97c690409ce4573a5857a0740d5d904":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a462f430bbbf44798fb7f538c5e84f0e","placeholder":"​","style":"IPY_MODEL_8aa9a397e9ac40fe9bdd3240dcaf6e31","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"e9bf8684551c43ee886c89919d847a76":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_ae9feeb21e904dcda5e42a728fc8aeb4","placeholder":"​","style":"IPY_MODEL_1324cfb1392e4ac3a8998a6cbac275e1","value":""}},"cd53da88ba5943e58c1772f018b2e2fa":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_ed5cb647d8e6447d842d51cf855d7ac9","style":"IPY_MODEL_353b9b4d378e4590ba3e3870d6ba47f5","value":false}},"e60cc8bd242e4787b2982153f536d3a0":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_3385b7468bd24d43abc60f4f7af7acff","style":"IPY_MODEL_e02f93bf98f14eb3be5b5cb724a48a28","tooltip":""}},"33a6a95105dd435383453275626f57bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05d4e00806db4c5d94ecb96f0acfabae","placeholder":"​","style":"IPY_MODEL_f92d1d324d3b41c1baa82a28e2a5ad94","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"4e7ba6aa463f4c31bef2989e8a269c56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"a462f430bbbf44798fb7f538c5e84f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa9a397e9ac40fe9bdd3240dcaf6e31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae9feeb21e904dcda5e42a728fc8aeb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1324cfb1392e4ac3a8998a6cbac275e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed5cb647d8e6447d842d51cf855d7ac9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353b9b4d378e4590ba3e3870d6ba47f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3385b7468bd24d43abc60f4f7af7acff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e02f93bf98f14eb3be5b5cb724a48a28":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"05d4e00806db4c5d94ecb96f0acfabae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f92d1d324d3b41c1baa82a28e2a5ad94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f25bb00b2db4fa6995249770c4d1007":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4014d4faa6344b7b5e4d6bf041b385b","placeholder":"​","style":"IPY_MODEL_934afe92c982426d9781d6ef8ada2720","value":"Connecting..."}},"a4014d4faa6344b7b5e4d6bf041b385b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"934afe92c982426d9781d6ef8ada2720":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}