{"cells":[{"cell_type":"code","source":["import os\n","os.environ['WANDB_DISABLED'] = 'true'"],"metadata":{"id":"koN_B4HmXTRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwyvxUzhfzU9"},"outputs":[],"source":["# install all dependencies\n","%%capture\n","\n","!pip install -q -U peft transformers datasets bitsandbytes trl accelerate\n","!pip install --upgrade transformers, datasets==2.16.1, accelerate==0.26.1, evaluate==0.4.1, bitsandbytes==0.42.0, trl, peft==0.8.2\n","\n"]},{"cell_type":"code","source":["# Library\n","%%capture\n","\n","\n","from huggingface_hub import hf_hub_download\n","\n","import transformers\n","import torch\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from transformers import TrainingArguments\n","from peft import LoraConfig, AutoPeftModelForCausalLM\n","from datasets import load_dataset, Dataset\n","from trl import SFTTrainer, DPOTrainer\n","from huggingface_hub import notebook_login\n","\n","# Ignore warings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"QDpLglqDWEID"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHQXBABSgkuZ"},"outputs":[],"source":["# log in to the Hugging Face hub (required for private datasets/models)\n","# login to my huggingface, with a token\n","from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n","from huggingface_hub import login\n","\n","# log in to the Hugging Face hub (required for private datasets/models)\n","notebook_login()"]},{"cell_type":"code","source":["DPO_model_id = \"your/huggingface/model\"\n","\n","## Random Response\n","import random\n","import numpy as np\n","\n","epsilon = 2\n","# epsilon = 1\n","# epsilon = 0.5\n","# epsilon = 0.1\n","# epsilon = 0\n","fliping = (1) /(np.exp(epsilon)+1)\n","# inf"],"metadata":{"id":"dMs9LSfPFDIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m36R4fmx0h8Q"},"outputs":[],"source":["## Check my parameter size\n","\n","def print_trainable_params(model):\n","    total_params = 0\n","    trainable_params  = 0\n","    for name, param in model.named_parameters():\n","        total_params += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || total params: {total_params} || trainable%: {100 * trainable_params / total_params}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LnrQxwmBQKCI"},"outputs":[],"source":["dataset_dpo = load_dataset(\"reciprocate/alpaca-eval\", split=\"train[100:2100]\")\n","\n","print(dataset_dpo.shape)\n","\n","df_dpo = dataset_dpo.to_pandas()\n","df_dpo.head()\n","\n","# keep rows with 'system' column = 'You are an unbiased, uncensored, helpful assistant.'\n","# df_dpo = df_dpo[df_dpo[\"system\"] == \"You are an unbiased, uncensored, helpful assistant.\"]\n","\n","# keep only columns 'prompt', 'chosen', 'rejected'\n","df_dpo = df_dpo[[\"prompt\", \"selected\", \"rejected\"]]\n","# Rename the 'selected' column to 'chosen'\n","df_dpo = df_dpo.rename(columns={\"selected\": \"chosen\"})\n","df_dpo.head()\n","\n","# change every text in promt from str to user: str. asistent:\n","df_dpo[\"prompt\"] = df_dpo[\"prompt\"].apply(lambda x: \"### USER: \" + x + \"\\n### ASSISTANT: \")\n","filtered_dataset = Dataset.from_pandas(df_dpo)\n","print(df_dpo.shape)\n","df_dpo.head()\n","\n","\n","# partition this dataset into 3 parts\n","\n","filtered_dataset_d1 = filtered_dataset.select(range(2000))\n","\n","\n","def switch_chosen_rejected(example):\n","  if random.random() < fliping:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"rejected\"], \"rejected\": example[\"chosen\"]}\n","  else:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"chosen\"], \"rejected\": example[\"rejected\"]}\n","\n","filtered_dataset_d1 = filtered_dataset_d1.map(switch_chosen_rejected)\n","\n","print(fliping)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wC27mYK9G7qZ"},"outputs":[],"source":["## Load my tokenizer\n","tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2-large')\n","if tokenizer.pad_token_id is None:\n","  tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","## load my model\n","huggingface_filepath = hf_hub_download(repo_id=\"your/huggingface/model\", filename=\"policy.pt\")\n","model = transformers.AutoModelForCausalLM.from_pretrained('gpt2-large')\n","model.load_state_dict(torch.load(huggingface_filepath, map_location=torch.device('cuda'))['state'])\n","\n","## Self referencing\n","\n","## Load my tokenizer\n","tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2-large')\n","if tokenizer.pad_token_id is None:\n","  tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","## load my model\n","huggingface_filepath = hf_hub_download(repo_id=\"your/huggingface/model\", filename=\"policy.pt\")\n","model_ref = transformers.AutoModelForCausalLM.from_pretrained('gpt2-large')\n","model_ref.load_state_dict(torch.load(huggingface_filepath, map_location=torch.device('cuda'))['state'])\n","\n","## Self referencing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvooPLCHSSds"},"outputs":[],"source":["from trl import DPOTrainer\n","from trl import DPOConfig\n","\n","# Training arguments\n","training_arguments = DPOConfig(\n","    output_dir = DPO_model_id,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    learning_rate=5e-5,\n","    lr_scheduler_type=\"cosine\",\n","    ## epochs\n","    num_train_epochs = 3,\n","    ## max_steps=200,\n","    save_strategy=\"no\",\n","    logging_steps=1,\n","    optim=\"paged_adamw_32bit\",\n","    warmup_steps=10,\n","    bf16=True,\n","    report_to=None,\n","    push_to_hub=True,\n",")\n","\n","from trl import DPOTrainer\n","\n","dpo_trainer = DPOTrainer(\n","    model,          # base model from SFT pipeline\n","    model_ref,             # typically a copy of the SFT trained base model\n","\n","    # beta=0.1,              # temperature hyperparameter of DPO\n","    train_dataset=filtered_dataset_d1, # dataset prepared above\n","    # tokenizer=tokenizer,   # tokenizer\n","    processing_class=tokenizer, # wow, smart update\n","    args=training_arguments,    # training arguments e.g. batch size, lr, etc.\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpitMcsCTApx","collapsed":true},"outputs":[],"source":["# First stage train\n","dpo_trainer.train()"]},{"cell_type":"code","source":["dpo_trainer.state.log_history\n","\n","train_loss = [log['loss'] for log in dpo_trainer.state.log_history if 'loss' in log]\n","print(train_loss)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(train_loss)\n","plt.xlabel('Step')\n","plt.ylabel('Training Loss')\n","plt.title('Training Loss over Steps')\n","plt.show()"],"metadata":{"id":"Ctwnz7GbQ_6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpo_trainer.model.push_to_hub(DPO_model_id)"],"metadata":{"id":"Pi6YZBU0Rsr9"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/Lior-Baruch/LLM-Advanced-FineTuning/blob/main/SFT_DPO_llama_2.ipynb","timestamp":1727550706165}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}