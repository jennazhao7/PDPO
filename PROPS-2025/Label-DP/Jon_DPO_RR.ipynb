{"cells":[{"cell_type":"code","source":["import os\n","os.environ['WANDB_DISABLED'] = 'true'"],"metadata":{"id":"wOAiVM0Yi-eU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwyvxUzhfzU9"},"outputs":[],"source":["# install all dependencies\n","%%capture\n","\n","!pip install -q -U peft transformers datasets bitsandbytes trl accelerate\n","!pip install --upgrade transformers==4.38.2, datasets==2.16.1, accelerate==0.26.1, evaluate==0.4.1, bitsandbytes==0.42.0, trl==0.7.11, peft==0.8.2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bA9fl7r5wCln"},"outputs":[],"source":["# Library\n","%%capture\n","\n","import torch\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from transformers import TrainingArguments\n","from peft import LoraConfig, AutoPeftModelForCausalLM\n","from datasets import load_dataset, Dataset\n","from trl import SFTTrainer, DPOTrainer\n","from huggingface_hub import notebook_login\n","\n","# Ignore warings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHQXBABSgkuZ"},"outputs":[],"source":["# log in to the Hugging Face hub (required for private datasets/models)\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m36R4fmx0h8Q"},"outputs":[],"source":["## Check my parameter size\n","\n","def print_trainable_params(model):\n","    total_params = 0\n","    trainable_params  = 0\n","    for name, param in model.named_parameters():\n","        total_params += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || total params: {total_params} || trainable%: {100 * trainable_params / total_params}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LnrQxwmBQKCI"},"outputs":[],"source":["#dataset_dpo = load_dataset(\"jondurbin/truthy-dpo-v0.1\", split=\"train[:150]\")\n","dataset_dpo = load_dataset(\"jondurbin/truthy-dpo-v0.1\", split=\"train[150:900]\")\n","print(dataset_dpo.shape)\n","\n","df_dpo = dataset_dpo.to_pandas()\n","df_dpo.head()\n","\n","# keep rows with 'system' column = 'You are an unbiased, uncensored, helpful assistant.'\n","df_dpo = df_dpo[df_dpo[\"system\"] == \"You are an unbiased, uncensored, helpful assistant.\"]\n","df_dpo.head()\n","\n","# keep only columns 'prompt', 'chosen', 'rejected'\n","df_dpo = df_dpo[[\"prompt\", \"chosen\", \"rejected\"]]\n","\n","# change every text in promt from str to user: str. asistent:\n","df_dpo[\"prompt\"] = df_dpo[\"prompt\"].apply(lambda x: \"### USER: \" + x + \"\\n### ASSISTANT: \")\n","filtered_dataset = Dataset.from_pandas(df_dpo)\n","print(df_dpo.shape)\n","df_dpo.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aBs43CWCTCu"},"outputs":[],"source":["## Random Response\n","import random\n","import numpy as np\n","\n","epsilon = 0.1\n","# epsilon = 0.5\n","# epsilon = 1\n","# epsilon = 2\n","\n","fliping = (1) /(np.exp(epsilon)+1)\n","# fliping = 0\n","\n","def switch_chosen_rejected(example):\n","  if random.random() < fliping:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"rejected\"], \"rejected\": example[\"chosen\"]}\n","  else:\n","    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"chosen\"], \"rejected\": example[\"rejected\"]}\n","\n","filtered_dataset = filtered_dataset.map(switch_chosen_rejected)\n","print(fliping)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wC27mYK9G7qZ"},"outputs":[],"source":["from peft import AutoPeftModelForCausalLM\n","from transformers import AutoTokenizer\n","import torch\n","\n","SFT_model_id = \"your/huggingface/model\"\n","\n","# Set quantization config (to save memory)\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_quant_type=\"nf4\"\n",")\n","\n","model = AutoPeftModelForCausalLM.from_pretrained(\n","    SFT_model_id, # location of saved SFT model\n","    low_cpu_mem_usage=True,\n","    torch_dtype=torch.float16,\n","    load_in_4bit=True,\n","    is_trainable=True,\n",")\n","model.config.use_cache = False\n","\n","model_ref = AutoPeftModelForCausalLM.from_pretrained(\n","    SFT_model_id,  # same model as the main one\n","    low_cpu_mem_usage=True,\n","    torch_dtype=torch.float16,\n","    load_in_4bit=True,\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(SFT_model_id)\n","# Set it to a new token to correctly attend to EOS tokens.\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8pMmGrynl8A"},"outputs":[],"source":["print_trainable_params(model)\n","print_trainable_params(model_ref)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvooPLCHSSds"},"outputs":[],"source":["DPO_model_id = \"your/huggingface/model\"\n","\n","# Training arguments\n","training_arguments = TrainingArguments(\n","    output_dir = DPO_model_id,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    learning_rate=5e-3,\n","    lr_scheduler_type=\"cosine\",\n","    ## epochs\n","    num_train_epochs = 7, #10\n","    ## max_steps=200,\n","    save_strategy=\"no\",\n","    logging_steps=10,\n","    optim=\"paged_adamw_32bit\",\n","    warmup_steps=10,\n","    bf16=True,\n","    # report_to=\"wandb\",\n","    push_to_hub=True,\n","    report_to =None,\n","\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TR5YNZMhSlri"},"outputs":[],"source":["from trl import DPOTrainer\n","\n","dpo_trainer = DPOTrainer(\n","    model,          # base model from SFT pipeline\n","    model_ref,             # typically a copy of the SFT trained base model\n","    beta=0.1,              # temperature hyperparameter of DPO\n","    train_dataset=filtered_dataset, # dataset prepared above\n","    tokenizer=tokenizer,   # tokenizer\n","    args=training_arguments,    # training arguments e.g. batch size, lr, etc.\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9trRaMHUjOW"},"outputs":[],"source":["print_trainable_params(dpo_trainer.model)\n","print_trainable_params(dpo_trainer.ref_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpitMcsCTApx"},"outputs":[],"source":["dpo_trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZyB3V7VxE9J"},"outputs":[],"source":["dpo_trainer.push_to_hub()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zS0euG-9KWv7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpKkfD_9KOIV"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/Lior-Baruch/LLM-Advanced-FineTuning/blob/main/SFT_DPO_llama_2.ipynb","timestamp":1727550706165}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}