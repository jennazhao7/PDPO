#!/bin/bash
#$ -N gpt2L_eval                 # Job name
#$ -q gpu@@jung_gpu              # GPU queue
#$ -pe smp 1                     # 1 CPU core (enough for data loading)
#$ -l gpu_card=1                 # Request 1 GPU
#$ -l gpu_mem=16G                # GPU memory
#$ -l h_vmem=32G                 # Host (CPU) memory
#$ -l mem_free=32G
#$ -l h_rt=04:00:00              # Wall time (4 hours - evaluation with API calls can take time)
#$ -cwd                          # Run job in current directory
#$ -m abe                        # Email alerts (abort, begin, end)
#$ -M jzhao7@nd.edu
#$ -V                            # Export environment variables

# === Setup environment ===
module load conda
conda activate pdpo
cd /users/jzhao7/PDPO

# === Check for OpenAI API Key ===
if [ -z "$OPENAI_API_KEY" ]; then
    echo "‚ùå ERROR: OPENAI_API_KEY environment variable is not set!"
    echo "   Please set it in your ~/.bashrc or export it before submitting the job"
    exit 1
fi

# === Configuration ===
YOUR_MODEL="Jennazhao7/gpt2-large-dpo-m1"  # Your DPO model (M1)
BASELINE_MODEL="Setpember/Jon_GPT2L_DPO_props_epi_point1"  # Baseline PROPS DPO model (epsilon=0.1)
OUTPUT_CSV="eval/props_win_tie_results_gpt2L.csv"
NUM_PROMPTS=100
BATCH_SIZE=4  # Smaller batch size for large model (reduce if OOM)
JUDGE_MODEL="gpt-4o-mini"  # Change to "gpt-4o" for better quality

# === Run evaluation ===
echo "üöÄ Starting evaluation..."
echo "Your Model (A): $YOUR_MODEL"
echo "Baseline (B): $BASELINE_MODEL"
echo "Judge: $JUDGE_MODEL"
echo "Batch Size: $BATCH_SIZE"
echo ""

python eval/truthy_gpt2L_eval_updated.py \
  --model_a "$YOUR_MODEL" \
  --model_b "$BASELINE_MODEL" \
  --n $NUM_PROMPTS \
  --batch_size $BATCH_SIZE \
  --judge_model "$JUDGE_MODEL" \
  --out_csv "$OUTPUT_CSV" \
  --n_votes 1

echo ""
echo "‚úÖ Evaluation complete!"
echo "üìä Results saved to: $OUTPUT_CSV"
echo "üìà Summary saved to: ${OUTPUT_CSV%.csv}_summary.csv"






